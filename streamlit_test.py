from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
import pandas as pd
import os
import re

df = pd.read_csv(r"ìŒì‹ì .csv", encoding="cp949")

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"

llm = ChatOpenAI()

prompt = ChatPromptTemplate.from_messages([("system" ,'''Your name is â€œê°€ë³¼ê¹Œ?â€ He is a Daegu travel recommendation expert 
                                            who recommends Daegu travel destinations. You must always answer in Korean.
                                            You must speak kindly.
                                            1. Destination
                                            2. Destination
                                            All you have to do is provide 5 destinations in this format.'''),
                                           ("user", "{message}")])

output_parser = StrOutputParser()

chain = prompt | llm | output_parser

# ì‚¬ìš©ì ì…ë ¥ê³¼ ì±„íŒ… ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
def response(message, history):
    history_langchain_format = []
    for msg in history:
        if isinstance(msg, HumanMessage):
            history_langchain_format.append(msg)
        elif isinstance(msg, AIMessage):
            history_langchain_format.append(msg)

    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    history_langchain_format.append(HumanMessage(content=message))

    # LangChain ChatOpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    gpt_response = chain.invoke({"message" : message})

    # ìƒì„±ëœ AI ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
    history_langchain_format.append(AIMessage(content=gpt_response))

    return gpt_response, history_langchain_format

# ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”
chat_history = []

#ì¶”ì²œ ëª¨ë¸

#ë¶ˆìš©ì–´ ì²˜ë¦¬
korean_stop_words = [
    "ì´", "ê·¸", "ì €", "ì—", "ê°€", "ì„", "ë¥¼", "ì˜", "ì€", "ëŠ”", "ë“¤", "ë¥¼", "ê³¼", "ì™€", "ì—ê²Œ", "ê²Œ",
    "í•©ë‹ˆë‹¤", "í•˜ëŠ”", "ìˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ë§ì€", "ë§ì´", "ë§ì€", "ë§ì´", "ëª¨ë“ ", "ëª¨ë‘", "í•œ", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ°ë°",
    "ë‚˜", "ë„ˆ", "ìš°ë¦¬", "ì €í¬", "ì´ëŸ°", "ê·¸ëŸ°", "ì €ëŸ°", "ì–´ë–¤", "ì–´ëŠ", "ê·¸ëŸ´", "ê²ƒ", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", 
    "ê·¸ëŸ¬ë‚˜", "ê·¸ë¦¬í•˜ì—¬", "ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¼ì—ë„", "ì´ì—", "ë•Œë¬¸ì—", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‹ˆê¹Œ", 
    "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ", "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ì–´ëŠ", "ëª¨ë‘", "ëª¨ë“ ", 
    "ê·¸ë˜ë„", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë©´", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ì´ëŸ¬í•œ", "ê·¸ëŸ¬í•œ", "ì €ëŸ¬í•œ", "ì´ëŸ¬í•œ", "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ",
    "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ëª¨ë‘", "ëª¨ë“ ", "ëª‡", "ëˆ„êµ¬", "ë¬´ìŠ¨", "ì–´ëŠ", "ì–¼ë§ˆë‚˜",
    "ë¬´ì—‡", "ë¬´ìŠ¨", "ì•„ë¬´", "ì—¬ê¸°", "ì €ê¸°", "ê±°ê¸°", "ê·¸ê³³", "ì´ê³³", "ì €ê³³", "ë¬´ì—‡", "ì•„ë¬´", "ëª¨ë‘", "ë§ˆì¹˜",
    "ë³´ë‹¤", "ë³´ì´ë‹¤", "ë“±", "ë“±ë“±", "ë“±ë“±ë“±"
    ]


def recommend(df, user_input, korean_stop_words):
    
    user_input_list = [user_input]
    
    all_about_data = df['all_about'].tolist()

    tfidf = TfidfVectorizer(stop_words=korean_stop_words)
    tfidf_matrix_all_about = tfidf.fit_transform(all_about_data)
    tfidf_matrix_input = tfidf.transform(user_input_list)

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ì‚¬
    cosine_sim = linear_kernel(tfidf_matrix_input, tfidf_matrix_all_about)

    top_place = cosine_sim.argsort()[0][-5:][::-1]

    recommended_places = []
    for idx in top_place:
        place_info = df.iloc[idx]
        recommended_places.append(f"{place_info['name']}: {place_info['info']}")

    for place in recommended_places:
        print(place)


# Streamlit ì„¤ì •
st.set_page_config(
    page_title="ëŒ€í‘¸ë¦¬ì¹´(DFRC)", 
    page_icon="ğŸ¥"
)

st.title('ëŒ€í‘¸ë¦¬ì¹´(DFRC)')
st.caption(':blue[ëŒ€êµ¬ì—¬í–‰ ì¶”ì²œ Chat ğŸ¥]')

# ì´ˆê¸° ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

messages = st.container()
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_input")

if user_input:
    # ì‚¬ìš©ì ì…ë ¥ ê¸°ë¡ ì¶”ê°€
    st.session_state['chat_history'].append({"role": "user", "message": user_input})

    # AI ì‘ë‹µ ìƒì„±
    ai_response, st.session_state['chat_history'] = response(user_input, st.session_state['chat_history'])

    # íŒ¨í„´ ë§¤ì¹­ ë° ì¶œë ¥
    pattern2 = re.findall(r'^.*?(?=1\.)', ai_response, re.DOTALL)

    if pattern2:
        for item in pattern2:
            with messages:
                st.write(f"AI: {item.strip()}")
                # ì¶”ì²œ í•¨ìˆ˜ í˜¸ì¶œ
                recommend(None, user_input, None)  # dfì™€ korean_stop_wordsëŠ” ì‹¤ì œ ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
    else:
        with messages:
            st.write(f"AI: {ai_response}")

# ì±„íŒ… ê¸°ë¡ ì¶œë ¥
with messages:
    for msg in st.session_state['chat_history']:
        role = "ì‚¬ìš©ì" if msg['role'] == "user" else "AI"
        st.write(f"{role}: {msg['message']}")
