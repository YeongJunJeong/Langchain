import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain

# Step 1: ë°ì´í„° ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
@st.cache_resource
def load_and_index_data(csv_path, model_name="all-MiniLM-L6-v2"):
    # CSV ë°ì´í„° ë¡œë“œ
    data = pd.read_csv(csv_path, encoding = "cp949")
    model = SentenceTransformer(model_name)
    
    # 'ìƒí˜¸ëª…', 'ì—…ì¢…ë¶„ë¥˜ëª…', 'ë„ë¡œëª…ì£¼ì†Œ', 'ë¦¬ë·°'ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ ê²€ìƒ‰ ë°ì´í„° ìƒì„±
    data['combined'] = data['ìƒí˜¸ëª…'] + " " + data['ì—…ì¢…ë¶„ë¥˜ëª…'] + " " + data['ë„ë¡œëª…ì£¼ì†Œ'] + " " + data['ë¦¬ë·°']
    
    # ë°ì´í„° ì„ë² ë”©
    embeddings = model.encode(data['combined'].tolist(), convert_to_tensor=False)
    
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return data, model, index

# Step 2: ìŒì‹ì  ê²€ìƒ‰
def search_restaurant(query, data, model, index, top_k=3):
    query_embedding = model.encode([query], convert_to_tensor=False)
    distances, indices = index.search(query_embedding, top_k)
    results = data.iloc[indices[0]]
    return results

# Step 3: ëŒ€í™” íë¦„ ì„¤ì •
def setup_chain(data, model, index):
    # LangChain ë©”ëª¨ë¦¬
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    
    # LangChain í”„ë¡¬í”„íŠ¸ ì„¤ì •
    prompt = ChatPromptTemplate.from_template(
        template="ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì í•©í•œ ìŒì‹ì ì„ ì¶”ì²œí•˜ì„¸ìš”.\nì§ˆë¬¸: {query}\në‹µë³€:"
    )
    
    # Conversational Chain ì„¤ì •
    chain = ConversationalRetrievalChain(
        llm=ChatOpenAI(model="gpt-3.5-turbo"),
        retriever=lambda q: search_restaurant(q, data, model, index),
        memory=memory,
        prompt=prompt,
    )
    return chain

# Step 4: Streamlit UI
def main():
    st.set_page_config(page_title="ìŒì‹ì  ì¶”ì²œ", layout="wide")
    st.title("ğŸ´ ìŒì‹ì  ì¶”ì²œ ì‹œìŠ¤í…œ")
    
    # ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ ìƒì„±
    data, model, index = load_and_index_data("ìŒì‹ì .csv")
    
    # LangChain Chain ì„¤ì •
    chain = setup_chain(data, model, index)
    
    # ì‚¬ìš©ì ì…ë ¥
    query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê°•ë‚¨ì— ìˆëŠ” ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ì¶”ì²œí•´ì¤˜")
    
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    
    # ëŒ€í™” ì²˜ë¦¬
    if query:
        results = search_restaurant(query, data, model, index)
        context = "\n".join(results['combined'].tolist())
        response = chain.run(query=query)
        
        # ëŒ€í™” ì´ë ¥ ì €ì¥
        st.session_state["chat_history"].append({"query": query, "response": response})
        
        # ê²°ê³¼ í‘œì‹œ
        st.subheader("ì¶”ì²œ ê²°ê³¼")
        for _, row in results.iterrows():
            st.write(f"**ìƒí˜¸ëª…**: {row['ìƒí˜¸ëª…']}")
            st.write(f"**ì—…ì¢…ë¶„ë¥˜ëª…**: {row['ì—…ì¢…ë¶„ë¥˜ëª…']}")
            st.write(f"**ë„ë¡œëª…ì£¼ì†Œ**: {row['ë„ë¡œëª…ì£¼ì†Œ']}")
            st.write(f"**ë¦¬ë·°**: {row['ë¦¬ë·°']}")
            st.markdown("---")
        
        st.subheader("AI ë‹µë³€")
        st.write(response)
    
    # ëŒ€í™” ì´ë ¥ í‘œì‹œ
    st.subheader("ëŒ€í™” ì´ë ¥")
    for history in st.session_state["chat_history"]:
        st.write(f"**ì§ˆë¬¸**: {history['query']}")
        st.write(f"**ë‹µë³€**: {history['response']}")
        st.markdown("---")

if __name__ == "__main__":
    main()
