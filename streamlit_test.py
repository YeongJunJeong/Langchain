import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
import pandas as pd
import re

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("ìŒì‹ì .csv", encoding="cp949")

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"

# LangChain ì„¤ì •
llm = ChatOpenAI(model=st.session_state["openai_model"])

system_message = SystemMessagePromptTemplate.from_template('''You are a recommendation expert who recommends restaurants in Daegu. 
                                            You must always answer in Korean.
                                            You must speak kindly.
                                            1. restaurant
                                            2. restaurant
                                            All you have to do is provide 5 restaurants in this format.''')
human_message = HumanMessagePromptTemplate.from_template("{message}")
prompt = ChatPromptTemplate.from_messages([system_message, human_message])

# ë¶ˆìš©ì–´ ì²˜ë¦¬ í•¨ìˆ˜
korean_stop_words = ["ì´", "ê·¸", "ì €", "ì—", "ê°€", "ì„", "ë¥¼", "ì˜", "ì€", "ëŠ”", "ë“¤", "ë¥¼", "ê³¼", "ì™€", "ì—ê²Œ", "ê²Œ",
    "í•©ë‹ˆë‹¤", "í•˜ëŠ”", "ìˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ë§ì€", "ë§ì´", "ë§ì€", "ë§ì´", "ëª¨ë“ ", "ëª¨ë‘", "í•œ", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ°ë°",
    "ë‚˜", "ë„ˆ", "ìš°ë¦¬", "ì €í¬", "ì´ëŸ°", "ê·¸ëŸ°", "ì €ëŸ°", "ì–´ë–¤", "ì–´ëŠ", "ê·¸ëŸ´", "ê²ƒ", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", 
    "ê·¸ëŸ¬ë‚˜", "ê·¸ë¦¬í•˜ì—¬", "ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¼ì—ë„", "ì´ì—", "ë•Œë¬¸ì—", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‹ˆê¹Œ", 
    "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ", "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ì–´ëŠ", "ëª¨ë‘", "ëª¨ë“ ", 
    "ê·¸ë˜ë„", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë©´", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ì´ëŸ¬í•œ", "ê·¸ëŸ¬í•œ", "ì €ëŸ¬í•œ", "ì´ëŸ¬í•œ", "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ",
    "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ëª¨ë‘", "ëª¨ë“ ", "ëª‡", "ëˆ„êµ¬", "ë¬´ìŠ¨", "ì–´ëŠ", "ì–¼ë§ˆë‚˜",
    "ë¬´ì—‡", "ë¬´ìŠ¨", "ì•„ë¬´", "ì—¬ê¸°", "ì €ê¸°", "ê±°ê¸°", "ê·¸ê³³", "ì´ê³³", "ì €ê³³", "ë¬´ì—‡", "ì•„ë¬´", "ëª¨ë‘", "ë§ˆì¹˜",
    "ë³´ë‹¤", "ë³´ì´ë‹¤", "ë“±", "ë“±ë“±", "ë“±ë“±ë“±"]

def preprocess_text(text, stop_words):
    for word in stop_words:
        text = text.replace(word, "")
    return text

df['all_about'] = df['all_about'].apply(lambda x: preprocess_text(x, korean_stop_words))

# ì¶”ì²œ í•¨ìˆ˜
def recommend(df, user_input, stop_words):
    user_input_list = [user_input]
    all_about_data = df['all_about'].tolist()
    tfidf = TfidfVectorizer(stop_words=stop_words)
    tfidf_matrix_all_about = tfidf.fit_transform(all_about_data)
    tfidf_matrix_input = tfidf.transform(user_input_list)
    cosine_sim = linear_kernel(tfidf_matrix_input, tfidf_matrix_all_about)
    top_place = cosine_sim.argsort()[0][-5:][::-1]

    recommended_places = []
    for idx in top_place:
        place_info = df.iloc[idx]
        recommended_places.append(f"{place_info['ìƒí˜¸ëª…']}: {place_info['ë¦¬ë·°']}")
    return recommended_places

# GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def response(user_input, chat_history):
    # ëŒ€í™” ì´ë ¥ìœ¼ë¡œ ë©”ì‹œì§€ êµ¬ì„±
    messages = [AIMessage(content=message) if i % 2 == 0 else HumanMessage(content=message) 
                for i, message in enumerate(chat_history)]
    messages.append(HumanMessage(content=user_input))

    # GPT ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
    result = llm(messages)
    return result.content, messages

# Streamlit UI ì„¤ì •
st.title('ëŒ€í‘¸ë¦¬ì¹´ (DFRC)')
st.caption(':blue[ëŒ€êµ¬ì—¬í–‰ ì¶”ì²œ Chat] ğŸ¥')

# ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
if user_input:
    # GPT ì‘ë‹µ ìƒì„±
    gpt_response, updated_history = response(user_input, st.session_state["chat_history"])
    st.session_state["chat_history"].extend([f"User: {user_input}", f"AI: {gpt_response}"])

    # ì¶”ì²œ ì‹¤í–‰
    recommendations = recommend(df, user_input, korean_stop_words)
    st.write("### ì¶”ì²œ ê²°ê³¼:")
    for rec in recommendations:
        st.write(rec)
