from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
import pandas as pd
import streamlit as st

with st.sidebar:
    openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
    
#if "openai_model" not in st.session_state:
    #st.session_state["openai_model"] = "gpt-3.5-turbo"

# CSV íŒŒì¼ ê²½ë¡œ
csv_file_path = 'ìŒì‹ì .csv'  # CSV íŒŒì¼ ê²½ë¡œë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”

# ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„
data = pd.read_csv(csv_file_path, encoding = 'cp949')

# í•„ìš”í•œ ì¹¼ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
if 'all_about' not in data.columns or 'ìƒí˜¸ëª…' not in data.columns:
    raise ValueError("CSV íŒŒì¼ì— 'all about' ë˜ëŠ” 'name' ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings()

# "all about" ë° "name" í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”
vectorstore = FAISS.from_texts(data['all_about'].tolist(), embeddings)

# Streamlit UI ì„¤ì •
st.title("ğŸ” ëŒ€í‘¸ë¦¬ì¹´ (DFRC)")
st.caption("ğŸœ ëŒ€êµ¬ê´‘ì—­ì‹œ ë§›ì§‘ ì¶”ì²œ ì±—ë´‡ ì„œë¹„ìŠ¤")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì˜ˆ) ìˆ˜ì„±ëª» ê·¼ì²˜ì— ê°€ì¡±ë“¤ê³¼ ì¡°ìš©í•˜ê²Œ ì™¸ì‹í•  ê³³ì„ ì¶”ì²œí•´ì¤˜"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # ì…ë ¥ í…ìŠ¤íŠ¸ ì„¤ì •
    input_text = prompt

    # ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ 5ê°œ í•­ëª© ê²€ìƒ‰
    similarities = vectorstore.similarity_search(input_text, k=5)

    # ìœ ì‚¬í•œ í•­ëª©ë“¤ì˜ name ì¶”ì¶œ
    similar_names = [data.loc[data['all_about'] == match.page_content, 'ìƒí˜¸ëª…'].values[0] for match in similarities]

    # ChatGPT ì´ˆê¸°í™”
    llm = OpenAI(temperature=0.7)

    # ChatGPTë¡œ ê°„ë‹¨í•œ ì„¤ëª… ìƒì„±
    explanations = []
    for name in similar_names:
        response = llm(f"'{name}'ì€ ëŒ€êµ¬ê´‘ì—­ì‹œì— ìˆëŠ” ì‹ë‹¹ì…ë‹ˆë‹¤. ê´€ë ¨ëœ ë‚´ìš©ì„ í•œ ì¤„ë¡œ ë§¤ìš° ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. í•­ìƒ ì¹œì ˆí•˜ê²Œ ì¡´ëŒ“ë§ë¡œ í•´ì£¼ì„¸ìš”")
        explanations.append(response)

    # ê²°ê³¼ ìƒì„± ë° ì¶œë ¥
    result = "\n\n".join([f"{idx}. {name}:\n{explanation}" for idx, (name, explanation) in enumerate(zip(similar_names, explanations), start=1)])

    # ë‹µë³€ ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": result})
    st.chat_message("assistant").write(result)
