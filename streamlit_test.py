import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import pandas as pd

# OpenAI LLM ì´ˆê¸°í™”
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
# OpenAI API í‚¤ ì„¤ì • ë° ì´ˆê¸°í™”
llm = ChatOpenAI()

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt = ChatPromptTemplate.from_messages([
    ("system", '''You are an expert in recommending great restaurants and delicious cafes in Daegu, South Korea.  
Listen carefully to the questions and recommend places relevant to the query.  
Always respond with recommendations when asked.  
Be polite and explain in Korean.  
Provide 5 concise examples with a brief description for each.'''),
    ("user", "{message}")
])
output_parser = StrOutputParser()
chain = prompt | llm | output_parser

# ëŒ€í™” ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(user_message):
    gpt_response = chain.invoke({"message": user_message})
    return gpt_response
# ì‚¬ìš©ì ì…ë ¥ê³¼ ì±„íŒ… ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
def response(message, history):
    history_langchain_format = []
    for msg in history:
        if isinstance(msg, HumanMessage):
            history_langchain_format.append(msg)
        elif isinstance(msg, AIMessage):
            history_langchain_format.append(msg)
    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    history_langchain_format.append(HumanMessage(content=message))
    # LangChain ChatOpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    gpt_response = chain.invoke({"message" : message})

# Streamlit UI ì„¤ì •
    # ìƒì„±ëœ AI ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
    history_langchain_format.append(AIMessage(content=gpt_response))
    return gpt_response, history_langchain_format
# ì±—ë´‡ UI êµ¬ì„±
st.set_page_config(
    page_title="ëŒ€í‘¸ë¦¬ì¹´(DFRC)", 
    page_icon="ğŸ¥"
)
    page_icon="ğŸ¥")

st.title('ëŒ€í‘¸ë¦¬ì¹´(DFRC)')
st.caption(':blue[ëŒ€êµ¬ì—¬í–‰ ì¶”ì²œ Chat ğŸ¥]')
# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
st.caption(':blue ëŒ€êµ¬ì—¬í–‰ ì¶”ì²œ Chat ğŸ¥')
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_input")
messages = st.container()

# ëŒ€í™” UI
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("user"):
        st.write(user_input)
# ëŒ€í™” ì´ë ¥ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

    # AI ì‘ë‹µ ìƒì„±
    ai_response = generate_response(user_input)
if user_input:
    ai_response, new_history = response(user_input, st.session_state['chat_history'])
    st.session_state['chat_history'] = new_history

    # AI ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("assistant"):
        st.write(ai_response)
    for message in st.session_state['chat_history']:
        if isinstance(message, HumanMessage):
            messages.chat_message("user").write(message.content)
        if isinstance(message, AIMessage):
            messages.chat_message("assistant").write(message.content)
