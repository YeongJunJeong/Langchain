import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv(r"C:\Users\jyjun\OneDrive\ë°”íƒ• í™”ë©´\ì±„ì°\dataset.csv", encoding="cp949")

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
    st.session_state["openai_model"] = "gpt-4o"

# OpenAI API í‚¤ ì„¤ì • ë° ì´ˆê¸°í™”
llm = ChatOpenAI()

prompt = ChatPromptTemplate.from_messages([
    ("system", '''You are an expert in recommending great restaurants and delicious cafes in Daegu, South Korea.  
Listen carefully to the questions and recommend places relevant to the query.  
Always respond with recommendations when asked.  
Be polite and explain in Korean.  
Provide 5 concise examples with a brief description for each.'''),
    ("user", "{message}")
])

output_parser = StrOutputParser()

chain = prompt | llm | output_parser

# ì‚¬ìš©ì ì…ë ¥ê³¼ ì±„íŒ… ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
def response(message, history):
    history_langchain_format = []
    for msg in history:
        if isinstance(msg, HumanMessage):
            history_langchain_format.append(msg)
        elif isinstance(msg, AIMessage):
            history_langchain_format.append(msg)

    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    history_langchain_format.append(HumanMessage(content=message))

    # LangChain ChatOpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    gpt_response = chain.invoke({"message" : message})
    gpt_response = chain.invoke({"message": message})

    # ìƒì„±ëœ AI ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
    history_langchain_format.append(AIMessage(content=gpt_response))

    return gpt_response, history_langchain_format

chat_history = []
korean_stop_words = [
    "ì´", "ê·¸", "ì €", "ì—", "ê°€", "ì„", "ë¥¼", "ì˜", "ì€", "ëŠ”", "ë“¤", "ë¥¼", "ê³¼", "ì™€", "ì—ê²Œ", "ê²Œ",
    "í•©ë‹ˆë‹¤", "í•˜ëŠ”", "ìˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ë§ì€", "ë§ì´", "ë§ì€", "ë§ì´", "ëª¨ë“ ", "ëª¨ë‘", "í•œ", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ°ë°",
    "ë‚˜", "ë„ˆ", "ìš°ë¦¬", "ì €í¬", "ì´ëŸ°", "ê·¸ëŸ°", "ì €ëŸ°", "ì–´ë–¤", "ì–´ëŠ", "ê·¸ëŸ´", "ê²ƒ", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", 
    "ê·¸ëŸ¬ë‚˜", "ê·¸ë¦¬í•˜ì—¬", "ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¼ì—ë„", "ì´ì—", "ë•Œë¬¸ì—", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‹ˆê¹Œ", 
    "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ", "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ì–´ëŠ", "ëª¨ë‘", "ëª¨ë“ ", 
    "ê·¸ë˜ë„", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë©´", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ì´ëŸ¬í•œ", "ê·¸ëŸ¬í•œ", "ì €ëŸ¬í•œ", "ì´ëŸ¬í•œ", "ì´ë ‡ê²Œ", "ê·¸ë ‡ê²Œ",
    "ì €ë ‡ê²Œ", "ì–´ë–»ê²Œ", "ì™œ", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ", "ëª¨ë‘", "ëª¨ë“ ", "ëª‡", "ëˆ„êµ¬", "ë¬´ìŠ¨", "ì–´ëŠ", "ì–¼ë§ˆë‚˜",
    "ë¬´ì—‡", "ë¬´ìŠ¨", "ì•„ë¬´", "ì—¬ê¸°", "ì €ê¸°", "ê±°ê¸°", "ê·¸ê³³", "ì´ê³³", "ì €ê³³", "ë¬´ì—‡", "ì•„ë¬´", "ëª¨ë‘", "ë§ˆì¹˜",
    "ë³´ë‹¤", "ë³´ì´ë‹¤", "ë“±", "ë“±ë“±", "ë“±ë“±ë“±"
    ]
# ì¶”ì²œ í•¨ìˆ˜
def recommend(df, user_input, korean_stop_words):
    user_input_list = [user_input]
    all_about_data = df['all_about'].tolist()
    tfidf = TfidfVectorizer(stop_words=korean_stop_words)
    tfidf_matrix_all_about = tfidf.fit_transform(all_about_data)
    tfidf_matrix_input = tfidf.transform(user_input_list)
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ì‚¬
    cosine_sim = linear_kernel(tfidf_matrix_input, tfidf_matrix_all_about)
    top_place = cosine_sim.argsort()[0][-5:][::-1]
    recommended_places = []
    for idx in top_place:
        place_info = df.iloc[idx]
        recommended_places.append(f"{place_info['name']}: {place_info['info']}")
    return recommended_places
# ì±—ë´‡ UI êµ¬ì„±
st.set_page_config(
    page_title="ëŒ€í‘¸ë¦¬ì¹´(DFRC)", 
    page_icon="ğŸ¥")

st.title('ëŒ€í‘¸ë¦¬ì¹´(DFRC)')
st.caption(':blue ëŒ€êµ¬ì—¬í–‰ ì¶”ì²œ Chat ğŸ¥')
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_input")
messages = st.container()

# ëŒ€í™” ì´ë ¥ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

if user_input:
    # AI ì‘ë‹µ ì²˜ë¦¬
    ai_response, new_history = response(user_input, st.session_state['chat_history'])
    st.session_state['chat_history'] = new_history

    # ì¶”ì²œ ê²°ê³¼ ìƒì„± ë° ì¶œë ¥
    recommended_places = recommend(df, user_input, korean_stop_words)
    # ëŒ€í™” ë©”ì‹œì§€ ì¶œë ¥
    for message in st.session_state['chat_history']:
        if isinstance(message, HumanMessage):
            messages.chat_message("user").write(message.content)
        if isinstance(message, AIMessage):
            messages.chat_message("assistant").write(message.content)
    # ì¶”ì²œ ê²°ê³¼ ì¶œë ¥
    with st.container():
        st.subheader("ì¶”ì²œ ì¥ì†Œ:")
        for place in recommended_places:
            st.write(place)
